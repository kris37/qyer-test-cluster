<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
<!--HA命名空间的逻辑名称
    <property>
        <name>dfs.nameservices</name>
        <value>qyer</value>
    </property>
-->
<!--after the first format namenode ,set this value false ,avoid format namenode -->
     <property>
        <name>dfs.namenode.support.allow.format</name>
        <value>false</value>
    </property>
   <!-- 保留200G空间:209715200  每块磁盘是2t 保留 10% ,10g:10485760  -->
    <property>
        <name>dfs.datanode.du.reserved</name>
        <value>209715200</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
     <property>
        <name>hadoop.tmp.dir</name>
        <value>/u01/hadoop/hdfs/data1/hadoop/tmp</value>
    </property>
     <!--namenode-->
    <!--name node的上持久化存储元数据和事务日志的路径。,以,号隔开,hdfs会把元数据冗余复制到这些目录，一般这些目录是不同的块设备-->
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>
          /u01/hadoop/hdfs/data1/hadoop/hdfs/nn/,
          /u01/hadoop/hdfs/data2/hadoop/hdfs/nn/
        </value>
    </property>
    <property>
        <name>dfs.name.edits.dir</name>
        <value>${dfs.namenode.name.dir}</value>
    </property>
<!-- The number of server threads for the datanode. namenode set 20logNode datanode set cup cores 5 -->
    <property>
        <name>dfs.namenode.handler.count</name>
        <value>21</value>
    </property>
    <property>
        <name>dfs.namenode.service.handler.count</name>
        <value>21</value>
    </property>
     <!-- datanode -->
    <!-- The number of server threads for the datanode. namenode set 20logNode datanode set cup cores 5 -->
    <property>
        <name>dfs.datanode.handler.count</name>
        <value>10</value>
    </property>
    <!--notice namenode 节点的data1 磁盘不做datanode 数据存储点-->
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>
          /u01/hadoop/hdfs/data1/hadoop/hdfs/dn/,
          /u01/hadoop/hdfs/data2/hadoop/hdfs/dn/,
          /u01/hadoop/hdfs/data3/hadoop/hdfs/dn/,
          /u01/hadoop/hdfs/data4/hadoop/hdfs/dn/,
          /u01/hadoop/hdfs/data5/hadoop/hdfs/dn/
        </value>
    </property>
    <property>
        <name>dfs.blocksize</name>
        <value>128m</value>
    </property>
    <!--黑白名单-->
     <property>
        <name>dfs.hosts</name>
        <value></value>
    </property>
    <property>
        <name>dfs.hosts.exclude</name>
        <value></value>
    </property>

    <!-- 坏2块盘,datanode才会stop -->
    <property>
        <name>dfs.datanode.failed.volumes.tolerated</name>
        <value>2</value>
    </property>

    <!--secondary ／checkpoint node settings 30min defalut is 1h-->
     <property>
        <name>dfs.namenode.checkpoint.period</name>
        <value>1800</value>
         <description>The number of seconds between two periodic checkpoints.
 		 </description>
    </property>

    <property>
      <name>dfs.namenode.checkpoint.txns</name>
      <value>50000</value>
    </property>
  <!--editlogs and segement numbers -->
    <property>
      <name>dfs.namenode.num.extra.edits.retained</name>
      <value>50000</value>
    </property>
     <property>
        <name>dfs.namenode.max.extra.edits.segments.retained</name>
         <value>1000</value>
       <description>The maximum number of extra edit log segments which should be retained
       beyond what is minimally necessary for a NN restart. When used in conjunction with
       dfs.namenode.num.extra.edits.retained, this configuration property serves to cap
       the number of extra edits files to a reasonable value.
       </description>
    </property>
     <!--dfs.namenode.checkpoint.dir,fs.checkpoint.dir is the same but all set-->
     <property>
  	   	<name>dfs.namenode.checkpoint.dir</name>
  		  <value>/u01/hadoop/hdfs/data5/hadoop/hdfs/dfs/namesecondary</value>
	   </property>
	   <property>
        <name>fs.checkpoint.dir</name>
        <value>/u01/hadoop/hdfs/data5/hadoop/hdfs/dfs/namesecondary</value>
      </property>
    <property>
       <name>dfs.namenode.checkpoint.edits.dir</name>
       <value>${dfs.namenode.checkpoint.dir}</value>
      <description>Determines where on the local filesystem the DFS secondary
        name node should store the temporary edits to merge.
      </description>
    </property>

<!--checkpoint and master httpservice，注意checkpoint 的edits和元数据信息存储目录的是和namenode 的一样的，secondary 才是写入到 checkpoint dir-->

  <property>
      <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
      <value>false</value>
  </property>
  <property>
      <name>dfs.namenode.backup.address</name>
      <value>10.1.10.32:50090</value>
  </property>
  <property>
      <name>dfs.http.address</name>
      <value>10.1.10.31:50070</value>
  </property>
  <property>
      <name>yarn.resourcemanager.hostname</name>
      <value>10.1.10.32</value>
  </property>

</configuration>
